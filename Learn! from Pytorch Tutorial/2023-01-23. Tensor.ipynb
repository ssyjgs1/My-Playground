{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNMM5OjmywDd740PMIvyuiB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# PyTorch Tutorial로 독학하기\n","- URL from : https://tutorials.pytorch.kr/beginner/blitz/tensor_tutorial.html\n","- URL from : https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html\n","- URL from : https://pytorch.org/docs/stable/generated/torch.stack.html"],"metadata":{"id":"C-Ch8sV7EWoN"}},{"cell_type":"markdown","source":["# Tensor\n","tensor는 array(배열)나 matrix(행렬)과 매우 유사한 특수한 자료구조다. PyTorch에서는 tensor를 사용하여 모델의 입출력뿐만 아닌, 모델의 매개변수를 encode(부호화)한다.  \n","GPU나 다른 연산 가속을 위한 특수한 하드웨어에서 실행할 수 있다는 점을 제외하면, tensor는 NumPy의 ndarray와 매우 유사하다."],"metadata":{"id":"qWXf-evcAu8H"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"3IyuiDhBAqkY","executionInfo":{"status":"ok","timestamp":1674452094413,"user_tz":-540,"elapsed":3113,"user":{"displayName":"이승윤","userId":"02154129095399496427"}}},"outputs":[],"source":["import torch\n","import numpy as np"]},{"cell_type":"markdown","source":["## tensor 초기화하기\n","tensor는 여러가지 방법으로 초기화할 수 있다. 아래에서 하나씩 해보자.\n","\n","### 데이터로부터 직접(directly) 생성하기\n","데이터로부터 직접 tensor를 생성할 수 있다. 데이터의 자료형(data type)은 자동으로 유추해서 만들어준다."],"metadata":{"id":"-fTo_NnKBJ7n"}},{"cell_type":"code","source":["data = [[1, 2], [3, 4]]\n","x_data = torch.tensor(data)"],"metadata":{"id":"pinfiBN1BHr0","executionInfo":{"status":"ok","timestamp":1674452094414,"user_tz":-540,"elapsed":11,"user":{"displayName":"이승윤","userId":"02154129095399496427"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["### NumPy 배열로부터 생성하기\n","tensor는 NumPy 배열로 생성할 수 있다. 그 반대도 가능하다."],"metadata":{"id":"Kg9IbbBzBhLg"}},{"cell_type":"code","source":["np_array = np.array(data)\n","x_np = torch.from_numpy(np_array)"],"metadata":{"id":"aMSuIwwtBf96","executionInfo":{"status":"ok","timestamp":1674452094414,"user_tz":-540,"elapsed":10,"user":{"displayName":"이승윤","userId":"02154129095399496427"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["### 다른 tensor로부터 생성하기\n","명시적으로 재정의(override)하지 않는다면, 인자로 주어진 tensor의 속성(모양(shape), 자료형(datatype))을 유지한다."],"metadata":{"id":"k-0ZdRF6BsSp"}},{"cell_type":"code","source":["x_ones = torch.ones_like(x_data) # x_data의 속성을 유지한다\n","print(f\"Ones Tensor : \\n {x_ones} \\n\")\n","\n","x_rand = torch.rand_like(x_data, dtype=torch.float) # x_data의 속성을 덮어쓴다\n","print(f\"Random Tensor : \\n {x_rand} \\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mCFEdPMcBrQg","executionInfo":{"status":"ok","timestamp":1674452094415,"user_tz":-540,"elapsed":10,"user":{"displayName":"이승윤","userId":"02154129095399496427"}},"outputId":"77097f22-91fa-4370-dd8c-8730a1a82c49"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Ones Tensor : \n"," tensor([[1, 1],\n","        [1, 1]]) \n","\n","Random Tensor : \n"," tensor([[0.2866, 0.9574],\n","        [0.9851, 0.1472]]) \n","\n"]}]},{"cell_type":"markdown","source":["### 무작위(random) 또는 상수(constant) 값을 사용하기  \n","```shape```은  tensor의 차원(dimension)을 나타내는 tuple로, 아래 함수들에서는 출력 tensor의 차원을 결정한다."],"metadata":{"id":"QK0ALCEjCRor"}},{"cell_type":"code","source":["shape = (2, 3,)\n","rand_tensor = torch.rand(shape)\n","ones_tensor = torch.ones(shape)\n","zeros_tensor = torch.zeros(shape)\n","\n","print(f\"Random Tensor : \\n {rand_tensor} \\n\")\n","print(f\"Ones Tensor : \\n {ones_tensor} \\n\")\n","print(f\"Zeros Tensor : \\n {zeros_tensor} \\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tx8gVSrwCO2X","executionInfo":{"status":"ok","timestamp":1674452094415,"user_tz":-540,"elapsed":7,"user":{"displayName":"이승윤","userId":"02154129095399496427"}},"outputId":"ee6243d9-22ef-4bcc-d7b6-58d87499ec60"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Random Tensor : \n"," tensor([[0.2371, 0.0587, 0.6256],\n","        [0.3414, 0.3823, 0.3501]]) \n","\n","Ones Tensor : \n"," tensor([[1., 1., 1.],\n","        [1., 1., 1.]]) \n","\n","Zeros Tensor : \n"," tensor([[0., 0., 0.],\n","        [0., 0., 0.]]) \n","\n"]}]},{"cell_type":"markdown","source":["## tensor의 속성(attribute)\n","tensor의 속성은 텐서의 모양(shape), 자료형( datatype), 및 어느 장치에 저장되는지를 나타낸다."],"metadata":{"id":"vlT4UgMCCwyV"}},{"cell_type":"code","source":["tensor = torch.rand(3, 4)\n","print(f\"Shape of tensor  : {tensor.shape}\")\n","print(f\"Datatype of tensor  : {tensor.dtype}\")\n","print(f\"Device tensor is stored on tensor  : {tensor.device}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"46BrT4g8CuD2","executionInfo":{"status":"ok","timestamp":1674452094415,"user_tz":-540,"elapsed":5,"user":{"displayName":"이승윤","userId":"02154129095399496427"}},"outputId":"6a199c64-7ae9-4b02-daae-7caeaf879c5b"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of tensor  : torch.Size([3, 4])\n","Datatype of tensor  : torch.float32\n","Device tensor is stored on tensor  : cpu\n"]}]},{"cell_type":"markdown","source":["## tensor 연산(operation)\n","전치(transposing), 인덱싱(indexing), 슬라이싱(slicing), 수학 계산, 선형 대수, 임의 샘플링(random sampling) 등, 100가지 이상의 tensor 연산이 가능하다.  \n","각 연산들은 일반적으로 CPU보다  빠른 GPU에서 실행할 수 있다."],"metadata":{"id":"2vCF2CJrDMlX"}},{"cell_type":"code","source":["# GPU가 존재한다면 tensor를 이동시켜보자\n","if torch.cuda.is_available() :\n","    tensor = tensor.to('cuda')\n","    print(f\"Device tensor is stored on : {tensor.device}\")"],"metadata":{"id":"q9Tfl5TiDGUS","executionInfo":{"status":"ok","timestamp":1674452099096,"user_tz":-540,"elapsed":4041,"user":{"displayName":"이승윤","userId":"02154129095399496427"}},"outputId":"1f86039e-bf90-4ec6-dde8-b52586fab07c","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Device tensor is stored on : cuda:0\n"]}]},{"cell_type":"markdown","source":["### NumPy식의 표준 인덱싱과 슬라이싱"],"metadata":{"id":"5BUSbD6aDxhq"}},{"cell_type":"code","source":["tensor = torch.ones(4, 4)\n","tensor[:, 1] = 0\n","print(tensor)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K2GClsmiDm2A","executionInfo":{"status":"ok","timestamp":1674452099096,"user_tz":-540,"elapsed":22,"user":{"displayName":"이승윤","userId":"02154129095399496427"}},"outputId":"80991d5a-3824-4fa8-acd8-8f6e6ed2535b"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]])\n"]}]},{"cell_type":"markdown","source":["### Tensor 합치기\n","```torch.cat```을 사용하여 주어진 차원에 따라 일련의 tensor를 연결할 수 있다. ```torch.cat```과 미묘하게 다른 또 다른 tensor 결합 연산으로는 ```torch.stack```이 있다."],"metadata":{"id":"xWgDBmLDEBvJ"}},{"cell_type":"code","source":["# torch.cat 사용하기\n","t1 =  torch.cat([tensor, tensor, tensor], dim=1)\n","print(t1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IyChfP_iD7gm","executionInfo":{"status":"ok","timestamp":1674452099097,"user_tz":-540,"elapsed":20,"user":{"displayName":"이승윤","userId":"02154129095399496427"}},"outputId":"67bac6e2-0402-452f-d8db-fd3b66647f78"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n","        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n","        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n","        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"]}]},{"cell_type":"code","source":["\"\"\"# torch.stack 사용하기\n","torch.stack(tensors, dim=0, *, out=None) # --> Tensor\"\"\"\n","# https://pytorch.org/docs/stable/generated/torch.stack.html"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"qNHoduzREUUW","executionInfo":{"status":"ok","timestamp":1674452099098,"user_tz":-540,"elapsed":19,"user":{"displayName":"이승윤","userId":"02154129095399496427"}},"outputId":"133609b3-68ae-4987-c39a-6936bfbdcf3b"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'# torch.stack 사용하기\\ntorch.stack(tensors, dim=0, *, out=None) # --> Tensor'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["### tensor 곱하기"],"metadata":{"id":"kKelIwOpFBKx"}},{"cell_type":"code","source":["# 요소별 곱(element-wise product) 계산하기\n","print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n","# 다른 문법으로는 :\n","print(f\"tensor * tensor \\n {tensor * tensor}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f0FesrSkE7yI","executionInfo":{"status":"ok","timestamp":1674452099098,"user_tz":-540,"elapsed":18,"user":{"displayName":"이승윤","userId":"02154129095399496427"}},"outputId":"ed30d261-1bd8-4361-ff1b-28ccbdc5ae53"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor.mul(tensor) \n"," tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]]) \n","\n","tensor * tensor \n"," tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]])\n"]}]},{"cell_type":"markdown","source":["두 tensor 간의 행렬 곱(matrix multiplication)을 계산해보자"],"metadata":{"id":"7gF1lAbRFXY9"}},{"cell_type":"code","source":["print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n","# 다른 문법으로는 :\n","print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nw_W3n-IFUU5","executionInfo":{"status":"ok","timestamp":1674452099098,"user_tz":-540,"elapsed":16,"user":{"displayName":"이승윤","userId":"02154129095399496427"}},"outputId":"f55e17c5-a1a3-4ae2-e646-009e1f9bcf73"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor.matmul(tensor.T) \n"," tensor([[3., 3., 3., 3.],\n","        [3., 3., 3., 3.],\n","        [3., 3., 3., 3.],\n","        [3., 3., 3., 3.]]) \n","\n","tensor @ tensor.T \n"," tensor([[3., 3., 3., 3.],\n","        [3., 3., 3., 3.],\n","        [3., 3., 3., 3.],\n","        [3., 3., 3., 3.]])\n"]}]},{"cell_type":"markdown","source":["### 바꿔치기(in-place) 연산\n","```_``` 접미사를 갖는 연산들은 바꿔치기(in-place) 연산이다. 예를 들어, ```x.copy_()```나 ```x.t_()```는 x를 변경하는 연산이다.\n","- 바꿔치기 연산은 메모리를 일부 절약하지만, 기록(history)이 즉시 삭제되어 도함수(derivative) 계산에 문제가 발생할 수 있다. 해서, 사용을 권장하지는 않는다고 한다."],"metadata":{"id":"J3PWS3RHFx8L"}},{"cell_type":"code","source":["print(tensor, \"\\n\")\n","tensor.add_(5)\n","print(tensor)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pe_b699PFpVO","executionInfo":{"status":"ok","timestamp":1674452099099,"user_tz":-540,"elapsed":16,"user":{"displayName":"이승윤","userId":"02154129095399496427"}},"outputId":"63307286-5968-4a08-e806-be3551a3b392"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]]) \n","\n","tensor([[6., 5., 6., 6.],\n","        [6., 5., 6., 6.],\n","        [6., 5., 6., 6.],\n","        [6., 5., 6., 6.]])\n"]}]},{"cell_type":"markdown","source":["## NumPy 변환(Bridge)\n","CPU 상의 tensor와 NumPy 배열은 메모리 공간을 공유하기 때문에, 하나를 변경하면 다른 하나도 변경된다.\n","\n","### tensor를 NumPy 배열로 변환하기"],"metadata":{"id":"OwmYBbYIGXYp"}},{"cell_type":"code","source":["t = torch.ones(5)\n","print(f\"t : {t}\")\n","n = t.numpy()\n","print(f\"n : {n}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AtGt_MxFGGEu","executionInfo":{"status":"ok","timestamp":1674452099099,"user_tz":-540,"elapsed":14,"user":{"displayName":"이승윤","userId":"02154129095399496427"}},"outputId":"cdeb9893-122e-4395-d5cd-b101669cf3c9"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["t : tensor([1., 1., 1., 1., 1.])\n","n : [1. 1. 1. 1. 1.]\n"]}]},{"cell_type":"markdown","source":["tensor의 변경 사항이 NumPy 배열에 반영된다."],"metadata":{"id":"V3lR79TuHEAZ"}},{"cell_type":"code","source":["t.add_(1)\n","print(f\"t : {t}\")\n","print(f\"n : {n}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6hyBIaX3GpKi","executionInfo":{"status":"ok","timestamp":1674452099099,"user_tz":-540,"elapsed":13,"user":{"displayName":"이승윤","userId":"02154129095399496427"}},"outputId":"67e38252-ff4d-429c-cba1-d586ff7437ac"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["t : tensor([2., 2., 2., 2., 2.])\n","n : [2. 2. 2. 2. 2.]\n"]}]},{"cell_type":"markdown","source":["### NumPy 배열을 tensor로 변환하기"],"metadata":{"id":"XgjPMPXLHQp5"}},{"cell_type":"code","source":["n = np.ones(5)\n","t = torch.from_numpy(n)"],"metadata":{"id":"k_CfjlpYHPEu","executionInfo":{"status":"ok","timestamp":1674452099099,"user_tz":-540,"elapsed":12,"user":{"displayName":"이승윤","userId":"02154129095399496427"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["NumPy 배열의 변경 사항이 tensor에 반영된다."],"metadata":{"id":"IqBhI6G-HYl0"}},{"cell_type":"code","source":["np.add(n, 1, out=n)\n","print(f\"t : {t}\")\n","print(f\"n : {n}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zO0mJ5FLHYCW","executionInfo":{"status":"ok","timestamp":1674452099099,"user_tz":-540,"elapsed":12,"user":{"displayName":"이승윤","userId":"02154129095399496427"}},"outputId":"5bd4eabf-ae39-45ec-8966-4417bafb9a17"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["t : tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n","n : [2. 2. 2. 2. 2.]\n"]}]}]}